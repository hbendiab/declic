#!/usr/bin/env python3
"""
Script pour cr√©er la base de donn√©es RAG pour les m√©tiers APEC
Transforme les 446 m√©tiers en embeddings et les stocke dans ChromaDB
"""

import json
import os
from pathlib import Path
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings

def setup_rag_database():
    """Configure la base de donn√©es RAG avec les m√©tiers APEC"""

    print("üöÄ CR√âATION DE LA BASE DE DONN√âES RAG")
    print("="*70)

    # √âTAPE 1: Charger les donn√©es m√©tiers
    print("\nüìÇ Chargement des donn√©es m√©tiers...")
    jobs_file = "data/jobs/apec-jobs.json"

    with open(jobs_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    jobs = data['jobs']
    print(f"‚úì {len(jobs)} m√©tiers charg√©s depuis {jobs_file}")

    # √âTAPE 2: Initialiser le mod√®le d'embeddings (fran√ßais)
    print("\nüß† Chargement du mod√®le d'embeddings (paraphrase-multilingual)...")
    print("   Note: T√©l√©chargement du mod√®le (~420 MB) si premi√®re fois...")

    # Mod√®le multilingue qui comprend bien le fran√ßais
    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    print("‚úì Mod√®le charg√©!")

    # √âTAPE 3: Cr√©er/Connecter √† ChromaDB
    print("\nüíæ Initialisation de ChromaDB...")

    # Cr√©er le dossier pour ChromaDB
    chroma_dir = Path("data/chroma_db")
    chroma_dir.mkdir(parents=True, exist_ok=True)

    # Initialiser le client ChromaDB
    client = chromadb.PersistentClient(
        path=str(chroma_dir),
        settings=Settings(
            anonymized_telemetry=False,
            allow_reset=True
        )
    )

    # Supprimer la collection si elle existe (pour r√©initialiser)
    try:
        client.delete_collection("jobs")
        print("‚úì Ancienne collection supprim√©e")
    except:
        pass

    # Cr√©er une nouvelle collection
    collection = client.create_collection(
        name="jobs",
        metadata={"description": "APEC jobs database"}
    )
    print(f"‚úì Collection 'jobs' cr√©√©e dans {chroma_dir}")

    # √âTAPE 4: Pr√©parer les documents pour l'embedding
    print(f"\nüìù Pr√©paration de {len(jobs)} m√©tiers pour vectorisation...")

    documents = []
    metadatas = []
    ids = []

    for idx, job in enumerate(jobs):
        # Cr√©er un texte riche pour l'embedding
        # Combine titre, description, missions, comp√©tences
        job_text = f"""
Titre: {job['title']}
Secteur: {job['sector']}
Description: {job.get('description', '')}
Missions: {job.get('missions', '')}
Comp√©tences: {', '.join(job.get('required_skills', [])[:5])}
Formation: {', '.join(job.get('required_education', []))}
Salaire: {job['salary']['min']}-{job['salary']['max']} {job['salary']['currency']}
        """.strip()

        documents.append(job_text)

        # M√©tadonn√©es pour filtrage et affichage
        metadatas.append({
            'title': job['title'],
            'sector': job['sector'],
            'salary_min': job['salary']['min'],
            'salary_max': job['salary']['max'],
            'slug': job['slug'],
            'url': job.get('url', '')
        })

        ids.append(f"job_{idx}")

    print("‚úì Documents pr√©par√©s")

    # √âTAPE 5: Cr√©er les embeddings et stocker dans ChromaDB
    print(f"\nüîÑ Cr√©ation des embeddings pour {len(documents)} m√©tiers...")
    print("   (Cela peut prendre 2-3 minutes...)")

    # Cr√©er les embeddings par batch pour plus d'efficacit√©
    batch_size = 32
    for i in range(0, len(documents), batch_size):
        batch_docs = documents[i:i+batch_size]
        batch_meta = metadatas[i:i+batch_size]
        batch_ids = ids[i:i+batch_size]

        # Cr√©er les embeddings
        embeddings = model.encode(batch_docs, show_progress_bar=True)

        # Ajouter √† ChromaDB
        collection.add(
            embeddings=embeddings.tolist(),
            documents=batch_docs,
            metadatas=batch_meta,
            ids=batch_ids
        )

        print(f"   ‚úì Batch {i//batch_size + 1}/{(len(documents) + batch_size - 1)//batch_size} ajout√©")

    print("\n‚úÖ TOUS LES EMBEDDINGS CR√â√âS ET STOCK√âS!")

    # √âTAPE 6: Test de recherche
    print("\nüß™ TEST DE RECHERCHE:")
    print("-" * 70)

    test_query = "m√©tiers cr√©atifs bien pay√©s"
    print(f"Question test: '{test_query}'")

    # Cr√©er l'embedding de la question
    query_embedding = model.encode([test_query])

    # Rechercher dans ChromaDB
    results = collection.query(
        query_embeddings=query_embedding.tolist(),
        n_results=3
    )

    print("\nüìä Top 3 r√©sultats:")
    for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0]), 1):
        print(f"\n{i}. {metadata['title']}")
        print(f"   Secteur: {metadata['sector']}")
        print(f"   Salaire: {metadata['salary_min']}-{metadata['salary_max']} EUR")

    # √âTAPE 7: Statistiques finales
    print("\n" + "="*70)
    print("‚úÖ BASE DE DONN√âES RAG CR√â√âE AVEC SUCC√àS!")
    print("="*70)
    print(f"‚úì M√©tiers vectoris√©s: {len(jobs)}")
    print(f"‚úì Emplacement: {chroma_dir}")
    print(f"‚úì Collection: 'jobs'")
    print(f"‚úì Mod√®le: paraphrase-multilingual-MiniLM-L12-v2")
    print("\nüí° Prochaine √©tape: Cr√©er l'API de recherche Next.js")
    print("="*70)

    return collection

if __name__ == "__main__":
    setup_rag_database()
